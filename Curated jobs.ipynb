{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fed23c8-f9cd-461d-b83b-544e13476ac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql.functions import collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7970ff3f-9ffc-496c-ba42-831ad7bf7588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def send_message(message, chat_ids):\n",
    "    TOKEN = dbutils.secrets.get(\"job_notification\", \"Telegram_Token\")\n",
    "    CHAT_ID = chat_ids\n",
    "    MESSAGE = message\n",
    "\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendMessage\"\n",
    "    for user in CHAT_ID:\n",
    "        payload = {\n",
    "            \"chat_id\": user,\n",
    "            \"text\": MESSAGE,\n",
    "            \"parse_mode\": \"HTML\"\n",
    "        }\n",
    "\n",
    "        res = requests.post(url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd0d1b9-d5db-4285-bdce-d63dc1358e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table('main_catalogue.jobs.users')\n",
    "chat_ids = df.filter(df.skill == \"Data Engineer\").select(collect_list('chat_id')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0092fb1c-1424-4c85-adad-43a9d14b894c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "linkedin_jobs = spark.table(\"staging_catalogue.jobs.linkedJobs\") \\\n",
    "                .select('url', 'title', 'company', 'location', 'hrs_ago', 'score')\n",
    "naukari_jobs = spark.table(\"staging_catalogue.jobs.naukariJobs\") \\\n",
    "                .select('url', 'title', 'companyName', 'location', 'hrs_ago', 'score')\n",
    "indeed_jobs = spark.table(\"staging_catalogue.jobs.indeedJobs\") \\\n",
    "                .select('url', 'title', 'company', 'location', 'hrs_ago', 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3c47d5-d26f-4746-ac00-f5756eeb9f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df = linkedin_jobs.union(naukari_jobs) \\\n",
    "                            .union(indeed_jobs)\n",
    "combined_df = combined_df.orderBy(combined_df[\"score\"].desc())\n",
    "combined_df.write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(\"main_catalogue.jobs.curated_jobs\")\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d74a1474-ef5f-46a7-b6e5-f8cf3faab12b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s = ''\n",
    "count = 1\n",
    "tc = 1\n",
    "tl = combined_df.count()\n",
    "for row in combined_df.collect():\n",
    "    # print(row)\n",
    "    s += f\"\"\"{tc}. <a href = \"{row[\"url\"]}\" >{row[\"title\"]}</a>\\n<b>{row[\"company\"]}</b>, <i>{row[\"location\"]}, {row[\"hrs_ago\"]}</i> \\n\\n\"\"\"\n",
    "    if count==20 or tc==tl:\n",
    "        send_message(s, chat_ids)\n",
    "        print(s)\n",
    "        count = 0\n",
    "        s = ''\n",
    "    count+=1\n",
    "    tc+=1"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Curated jobs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
