{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0b63f1-03cb-4763-9b4c-6b7c754455f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install -q requests beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e5fc195-dab1-46d3-871c-8cf911d80471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c905300-41f6-4f67-9983-3214774dbc8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from pyspark.sql.functions import col, current_timestamp, timestamp_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8d1c42-e852-4106-a50b-0a6dd9afa587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    page_to_scrape = requests.get(url)\n",
    "    soup = BeautifulSoup(page_to_scrape.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b71c7035-07ef-4d93-8b96-15edb4d965d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_job_details(url):\n",
    "    soup = get_soup(url)\n",
    "    d = json.loads(soup.find(\"script\", attrs={\"type\": \"application/ld+json\"}).text)\n",
    "    soup1 = BeautifulSoup(d['description'], \"html.parser\")\n",
    "    x = (soup1.get_text(separator=' ', strip=True))\n",
    "    soup2 = BeautifulSoup(x, \"html.parser\")\n",
    "    d['description'] =(soup2.get_text(separator=' ', strip=True))\n",
    "    fields = ['title', 'description', 'datePosted', 'skills']\n",
    "    selected = {k:v for k,v in d.items() if k in fields}\n",
    "    selected['url'] = url\n",
    "    selected['company'] = d['hiringOrganization']['name']\n",
    "    selected['location'] = d['jobLocation']['address']['addressLocality']\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e632567a-bb7d-477c-8bff-988509c42bc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "linkedin"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.linkedin.com/jobs/search?keywords=Data+Engineer&location=India&f_TPR=r86400&f_E=2%2C3\"\n",
    "\n",
    "soup = get_soup(url)\n",
    "data = soup.findAll(\"a\", attrs={\"class\":\"base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2] outline-offset-[4px]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5ba3062-7c9b-4dbe-89f4-8ffb7b657854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "details = []\n",
    "for job in data:\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        details.append(get_job_details(job['href']))\n",
    "    except:\n",
    "        pass\n",
    "print(f\"{len(data)-len(details)} jobs skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe655549-021d-4bab-87c7-432e1d29487e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(details)\n",
    "df = df.withColumn(\"hrs_ago\", timestamp_diff(\"hour\",  col(\"datePosted\").cast(\"timestamp\"), current_timestamp()))\n",
    "df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"raw_catalogue.jobs.linkedJobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe1ce3b-186d-444b-bbb2-14c9d8638354",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"url\":{\"format\":{\"preset\":\"string-preset-url\",\"locale\":\"en\"}}}},\"syncTimestamp\":1772257618367}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "getting linkedin jobs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
